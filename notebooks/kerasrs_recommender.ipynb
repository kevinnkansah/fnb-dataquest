{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7002c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_rs\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ab6da",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6eaf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv', encoding='ISO-8859-1')\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "df = df.dropna(subset=['CustomerID'])\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Interaction'] = df['Quantity'] * df['UnitPrice']\n",
    "df = df[df['Interaction'] > 0]\n",
    "customer_ids = df['CustomerID'].unique().tolist()\n",
    "product_ids = df['StockCode'].unique().tolist()\n",
    "customer2idx = {x: i for i, x in enumerate(customer_ids)}\n",
    "product2idx = {x: i for i, x in enumerate(product_ids)}\n",
    "df['customer_idx'] = df['CustomerID'].map(customer2idx)\n",
    "df['product_idx'] = df['StockCode'].map(product2idx)\n",
    "num_users = len(customer2idx)\n",
    "num_products = len(product2idx)\n",
    "df['normalized_interaction'] = df['Interaction'] / df['Interaction'].max()\n",
    "\n",
    "# Sort by time to prevent training on future data\n",
    "df = df.sort_values('InvoiceDate')\n",
    "\n",
    "X = df[['customer_idx', 'product_idx']].values\n",
    "y = df['normalized_interaction'].values\n",
    "\n",
    "# Use the first 80% for training, last 20% for testing (time-based split)\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b8449",
   "metadata": {},
   "source": [
    "## Retrieval Model (Two-Tower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b9128f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalModel(keras.Model):\n",
    "    def __init__(self, num_users, num_products, embedding_dim=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.user_embedding = layers.Embedding(num_users, embedding_dim)\n",
    "        self.product_embedding = layers.Embedding(num_products, embedding_dim)\n",
    "        self.retrieval = keras_rs.layers.BruteForceRetrieval(k=10, return_scores=False)\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "        self._candidates_set = False\n",
    "\n",
    "    def update_candidates(self):\n",
    "        product_indices = np.arange(self.product_embedding.input_dim)\n",
    "        product_embs = self.product_embedding(product_indices)\n",
    "        self.retrieval.update_candidates(product_embs, product_indices)\n",
    "        self._candidates_set = True\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        user_emb = self.user_embedding(inputs[:, 0])\n",
    "        product_emb = self.product_embedding(inputs[:, 1])\n",
    "        result = {\"user_emb\": user_emb, \"product_emb\": product_emb}\n",
    "        if not training and self._candidates_set:\n",
    "            result[\"predictions\"] = self.retrieval(user_emb)\n",
    "        return result\n",
    "\n",
    "    def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
    "        user_emb = y_pred[\"user_emb\"]\n",
    "        product_emb = self.product_embedding(x[:, 1])\n",
    "        labels = keras.ops.expand_dims(y, -1)\n",
    "        scores = keras.ops.sum(keras.ops.multiply(user_emb, product_emb), axis=1, keepdims=True)\n",
    "        return self.loss_fn(labels, scores, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cba6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/fnb-dataquest/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py:396: UserWarning: `build()` was called on layer 'retrieval_model_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 2.2947e-05 - val_loss: 3.4508e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 2.2947e-05 - val_loss: 3.4508e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 2.3534e-05 - val_loss: 3.4366e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 2.3534e-05 - val_loss: 3.4366e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.2432e-05 - val_loss: 3.4227e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.2432e-05 - val_loss: 3.4227e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 2.2965e-05 - val_loss: 3.4092e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 2.2965e-05 - val_loss: 3.4092e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.2407e-05 - val_loss: 3.3960e-05\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 2.2407e-05 - val_loss: 3.3960e-05\n"
     ]
    }
   ],
   "source": [
    "retrieval_model = RetrievalModel(num_users, num_products, embedding_dim=32)\n",
    "retrieval_model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.05))\n",
    "retrieval_history = retrieval_model.fit(\n",
    "    X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test), verbose=1\n",
    ")\n",
    "retrieval_model.update_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159dfdd8",
   "metadata": {},
   "source": [
    "## Ranking Model (Deep Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b81bfa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(keras.Model):\n",
    "    def __init__(self, num_users, num_products, embedding_dim=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.user_embedding = layers.Embedding(num_users, embedding_dim)\n",
    "        self.product_embedding = layers.Embedding(num_products, embedding_dim)\n",
    "        self.ratings = keras.Sequential([\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_emb = self.user_embedding(inputs[:, 0])\n",
    "        product_emb = self.product_embedding(inputs[:, 1])\n",
    "        concat = keras.ops.concatenate([user_emb, product_emb], axis=1)\n",
    "        return self.ratings(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "954f77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 2.8758e-05 - root_mean_squared_error: 0.0051 - val_loss: 1.4457e-05 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 2.8758e-05 - root_mean_squared_error: 0.0051 - val_loss: 1.4457e-05 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.9637e-06 - root_mean_squared_error: 0.0014 - val_loss: 1.3380e-05 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.9637e-06 - root_mean_squared_error: 0.0014 - val_loss: 1.3380e-05 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.6426e-06 - root_mean_squared_error: 0.0013 - val_loss: 1.3064e-05 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.6426e-06 - root_mean_squared_error: 0.0013 - val_loss: 1.3064e-05 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 8.1845e-07 - root_mean_squared_error: 8.8914e-04 - val_loss: 1.2937e-05 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 8.1845e-07 - root_mean_squared_error: 8.8914e-04 - val_loss: 1.2937e-05 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.5624e-06 - root_mean_squared_error: 0.0012 - val_loss: 1.2869e-05 - val_root_mean_squared_error: 0.0036\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 1.5624e-06 - root_mean_squared_error: 0.0012 - val_loss: 1.2869e-05 - val_root_mean_squared_error: 0.0036\n"
     ]
    }
   ],
   "source": [
    "ranking_model = RankingModel(num_users, num_products, embedding_dim=32)\n",
    "ranking_model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=0.05),\n",
    ")\n",
    "ranking_history = ranking_model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48164a5",
   "metadata": {},
   "source": [
    "## Beyond-Accuracy Metrics with KerasRS\n",
    "\n",
    "KerasRS provides advanced metrics such as Mean Reciprocal Rank (MRR), nDCG, and coverage/diversity. For production, consider using these for a more holistic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "424a8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_rs.metrics import MeanReciprocalRank , NDCG\n",
    "mrr_metric = MeanReciprocalRank()\n",
    "ndcg_metric = NDCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802849",
   "metadata": {},
   "source": [
    "## References\n",
    "- [KerasRS API Documentation](https://keras.io/keras_rs/api/)\n",
    "- [KerasRS Basic Retrieval Example](https://keras.io/keras_rs/examples/basic_retrieval/)\n",
    "- [KerasRS Basic Ranking Example](https://keras.io/keras_rs/examples/basic_ranking/)\n",
    "- [KerasRS Deep Recommender Example](https://keras.io/keras_rs/examples/deep_recommender/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81c5f4",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation with KerasRS\n",
    "\n",
    "Let's evaluate our models using advanced ranking metrics provided by KerasRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e55830e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranking Model Performance:\n",
      "Mean Reciprocal Rank (MRR): 0.0000\n",
      "Mean Average Precision (MAP): 0.0000\n",
      "Discounted Cumulative Gain (DCG): 0.0002\n",
      "Normalized DCG (nDCG): 0.2050\n"
     ]
    }
   ],
   "source": [
    "from keras_rs.metrics import MeanReciprocalRank, MeanAveragePrecision, DCG, NDCG\n",
    "\n",
    "def get_ranking_eval_data(model, X, y, num_products, group_size=20):\n",
    "    user_indices = np.unique(X[:, 0])\n",
    "    np.random.shuffle(user_indices)\n",
    "    user_indices = user_indices[:group_size]\n",
    "    y_true, y_pred = [], []\n",
    "    for user in user_indices:\n",
    "        user_mask = X[:, 0] == user\n",
    "        user_products = X[user_mask][:, 1]\n",
    "        all_products = np.arange(num_products)\n",
    "        labels = np.zeros(num_products)\n",
    "        labels[user_products] = y[user_mask]\n",
    "        user_input = np.column_stack([np.repeat(user, num_products), all_products])\n",
    "        scores = model.predict(user_input, verbose=0).flatten()\n",
    "        y_true.append(labels)\n",
    "        y_pred.append(scores)\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "y_true, y_pred = get_ranking_eval_data(ranking_model, X_test, y_test, num_products)\n",
    "mrr = MeanReciprocalRank()(y_true, y_pred)\n",
    "map_score = MeanAveragePrecision()(y_true, y_pred)\n",
    "dcg = DCG()(y_true, y_pred)\n",
    "ndcg = NDCG()(y_true, y_pred)\n",
    "print(\"\\nRanking Model Performance:\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n",
    "print(f\"Discounted Cumulative Gain (DCG): {dcg:.4f}\")\n",
    "print(f\"Normalized DCG (nDCG): {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e59ff9",
   "metadata": {},
   "source": [
    "## Generate and Evaluate Recommendations\n",
    "\n",
    "Let's generate recommendations for sample users and evaluate their quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dce2a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Recommendations for User 17850.0:\n",
      "  StockCode                         Description  UnitPrice  Predicted_Score\n",
      "0     20619            TROPICAL PASSPORT COVER        0.75         0.002213\n",
      "1    16162M        THE KING GIFT BAG 25x24x12cm       0.42         0.002075\n",
      "2     22743  MAKE YOUR OWN FLOWERPOWER CARD KIT       2.95         0.001939\n",
      "3    79161A    ST GEORGE SET OF 10 PARTY LIGHTS       2.95         0.001902\n",
      "4     21719         LOVELY BONBON STICKER SHEET       0.85         0.001720\n",
      "5     22195        LARGE HEART MEASURING SPOONS       1.65         0.001703\n",
      "6     22680       FRENCH BLUE METAL DOOR SIGN 5       1.25         0.001621\n",
      "7     21561     DINOSAUR LUNCH BOX WITH CUTLERY       2.55         0.001601\n",
      "8     20617         FIRST CLASS PASSPORT COVER        2.10         0.001586\n",
      "9    35004P          SET OF 3 PINK FLYING DUCKS       5.45         0.001538\n",
      "\n",
      "User's Actual Purchases:\n",
      "     StockCode                          Description  UnitPrice  Quantity\n",
      "0       85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55         6\n",
      "1        71053                  WHITE METAL LANTERN       3.39         6\n",
      "2       84406B       CREAM CUPID HEARTS COAT HANGER       2.75         8\n",
      "3       84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39         6\n",
      "4       84029E       RED WOOLLY HOTTIE WHITE HEART.       3.39         6\n",
      "5        22752         SET 7 BABUSHKA NESTING BOXES       7.65         2\n",
      "6        21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         6\n",
      "7        22633               HAND WARMER UNION JACK       1.85         6\n",
      "8        22632            HAND WARMER RED POLKA DOT       1.85         6\n",
      "60      82494L          WOODEN FRAME ANTIQUE WHITE        2.55         6\n",
      "59       82482    WOODEN PICTURE FRAME WHITE FINISH       2.10         6\n",
      "58       82486    WOOD S/3 CABINET ANT WHITE FINISH       6.95         4\n",
      "57       82483   WOOD 2 DRAWER CABINET WHITE FINISH       4.95         2\n",
      "55       21071       VINTAGE BILLBOARD DRINK ME MUG       1.06         6\n",
      "54       21871                  SAVE THE PLANET MUG       1.06         6\n",
      "53       37370           RETRO COFFEE MUGS ASSORTED       1.06         6\n",
      "52       20679                EDWARDIAN PARASOL RED       4.95         6\n",
      "56       21068      VINTAGE BILLBOARD LOVE/HATE MUG       1.06         6\n",
      "290     82494L          WOODEN FRAME ANTIQUE WHITE        2.55        12\n",
      "294      22803             IVORY EMBROIDERED QUILT       35.75         2\n",
      "281    15056BL              EDWARDIAN PARASOL BLACK       4.95         6\n",
      "416     85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55         8\n",
      "424      82483   WOOD 2 DRAWER CABINET WHITE FINISH       4.95         4\n",
      "417      71053                  WHITE METAL LANTERN       3.39         8\n",
      "3129     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         4\n",
      "3124     22411    JUMBO SHOPPER VINTAGE RED PAISLEY       1.65         6\n",
      "3121     82486    WOOD S/3 CABINET ANT WHITE FINISH       6.95         2\n",
      "3194    84406B       CREAM CUPID HEARTS COAT HANGER       2.75         6\n",
      "3820    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39         8\n",
      "3808    85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55        12\n",
      "3809     71053                  WHITE METAL LANTERN       3.39        12\n",
      "3805     22752         SET 7 BABUSHKA NESTING BOXES       7.65         4\n",
      "3804    84029E       RED WOOLLY HOTTIE WHITE HEART.       3.39         8\n",
      "4179     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         8\n",
      "4542     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25        12\n",
      "4541     22803             IVORY EMBROIDERED QUILT       35.75         3\n",
      "4538    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39        12\n",
      "4532     21071       VINTAGE BILLBOARD DRINK ME MUG       1.06        12\n",
      "4533     21068      VINTAGE BILLBOARD LOVE/HATE MUG       1.06        12\n",
      "4531     37370           RETRO COFFEE MUGS ASSORTED       1.06        12\n",
      "4528    84406B       CREAM CUPID HEARTS COAT HANGER       2.75        12\n",
      "4526    85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.95        12\n",
      "4543     22632            HAND WARMER RED POLKA DOT       1.85        12\n",
      "4544     22633               HAND WARMER UNION JACK       1.85        12\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(model, user_id, df, customer2idx, product2idx, top_n=10):\n",
    "    user_idx = customer2idx[user_id]\n",
    "    all_products = np.arange(len(product2idx))\n",
    "    user_input = np.column_stack([np.repeat(user_idx, len(product2idx)), all_products])\n",
    "    scores = model.predict(user_input, verbose=0).flatten()\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "    idx2product = {v: k for k, v in product2idx.items()}\n",
    "    recommended_products = [idx2product[idx] for idx in top_indices]\n",
    "    recommendations_data = []\n",
    "    for idx, product_id in zip(top_indices, recommended_products):\n",
    "        product_info = df[df['StockCode'] == product_id].iloc[0]\n",
    "        recommendations_data.append({\n",
    "            'StockCode': product_id,\n",
    "            'Description': product_info['Description'],\n",
    "            'UnitPrice': product_info['UnitPrice'],\n",
    "            'Predicted_Score': scores[idx]\n",
    "        })\n",
    "    recommendations = pd.DataFrame(recommendations_data)\n",
    "    return recommendations\n",
    "\n",
    "sample_user_id = df['CustomerID'].iloc[0]\n",
    "recommendations = get_recommendations(ranking_model, sample_user_id, df, customer2idx, product2idx)\n",
    "print(f\"\\nTop 10 Recommendations for User {sample_user_id}:\")\n",
    "print(recommendations)\n",
    "user_actual = df[df['CustomerID'] == sample_user_id][\n",
    "    ['StockCode', 'Description', 'UnitPrice', 'Quantity']\n",
    "].drop_duplicates()\n",
    "print(f\"\\nUser's Actual Purchases:\")\n",
    "print(user_actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
