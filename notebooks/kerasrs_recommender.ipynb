{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc034d0e",
   "metadata": {},
   "source": [
    "# KerasRS Recommender System Example\n",
    "\n",
    "This notebook demonstrates how to build retrieval and ranking recommender models using the KerasRS API, following official KerasRS examples and best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7002c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_rs\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ab6da",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6eaf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# (Update the path if needed)\n",
    "df = pd.read_csv('../data/data.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Remove cancelled orders (those starting with 'C')\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "# Remove rows with missing CustomerID\n",
    "df = df.dropna(subset=['CustomerID'])\n",
    "# Convert InvoiceDate to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "# Create interaction strength\n",
    "df['Interaction'] = df['Quantity'] * df['UnitPrice']\n",
    "df = df[df['Interaction'] > 0]\n",
    "\n",
    "# Encode users and products\n",
    "customer_ids = df['CustomerID'].unique().tolist()\n",
    "product_ids = df['StockCode'].unique().tolist()\n",
    "customer2idx = {x: i for i, x in enumerate(customer_ids)}\n",
    "product2idx = {x: i for i, x in enumerate(product_ids)}\n",
    "df['customer_idx'] = df['CustomerID'].map(customer2idx)\n",
    "df['product_idx'] = df['StockCode'].map(product2idx)\n",
    "num_users = len(customer2idx)\n",
    "num_products = len(product2idx)\n",
    "df['normalized_interaction'] = df['Interaction'] / df['Interaction'].max()\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[['customer_idx', 'product_idx']].values\n",
    "y = df['normalized_interaction'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b8449",
   "metadata": {},
   "source": [
    "## Retrieval Model (Two-Tower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9128f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalModel(keras.Model):\n",
    "    def __init__(self, num_users, num_products, embedding_dim=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.user_embedding = layers.Embedding(num_users, embedding_dim)\n",
    "        self.product_embedding = layers.Embedding(num_products, embedding_dim)\n",
    "        self.retrieval = keras_rs.layers.BruteForceRetrieval(k=10, return_scores=False)\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "        self._candidates_set = False\n",
    "\n",
    "    def update_candidates(self):\n",
    "        # Set candidate embeddings for retrieval\n",
    "        product_indices = np.arange(self.product_embedding.input_dim)\n",
    "        product_embs = self.product_embedding(product_indices)\n",
    "        self.retrieval.update_candidates(product_embs, product_indices)\n",
    "        self._candidates_set = True\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        user_emb = self.user_embedding(inputs[:, 0])\n",
    "        product_emb = self.product_embedding(inputs[:, 1])\n",
    "        result = {\"user_emb\": user_emb, \"product_emb\": product_emb}\n",
    "        if not training and self._candidates_set:\n",
    "            # Only call retrieval if candidates are set\n",
    "            result[\"predictions\"] = self.retrieval(user_emb)\n",
    "        return result\n",
    "\n",
    "    def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
    "        user_emb = y_pred[\"user_emb\"]\n",
    "        product_emb = self.product_embedding(x[:, 1])\n",
    "        labels = keras.ops.expand_dims(y, -1)\n",
    "        scores = keras.ops.sum(keras.ops.multiply(user_emb, product_emb), axis=1, keepdims=True)\n",
    "        return self.loss_fn(labels, scores, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cba6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/Documents/fnb-dataquest/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py:396: UserWarning: `build()` was called on layer 'retrieval_model_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.8586e-05 - val_loss: 2.2233e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.8586e-05 - val_loss: 2.2233e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.3347e-05 - val_loss: 2.2067e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.3347e-05 - val_loss: 2.2067e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.2985e-05 - val_loss: 2.1905e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.2985e-05 - val_loss: 2.1905e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.5163e-05 - val_loss: 2.1748e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.5163e-05 - val_loss: 2.1748e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.9296e-05 - val_loss: 2.1596e-05\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.9296e-05 - val_loss: 2.1596e-05\n"
     ]
    }
   ],
   "source": [
    "retrieval_model = RetrievalModel(num_users, num_products, embedding_dim=32)\n",
    "retrieval_model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.05))\n",
    "retrieval_history = retrieval_model.fit(\n",
    "    X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test), verbose=1\n",
    ")\n",
    "\n",
    "# IMPORTANT: Update candidates before using retrieval for inference\n",
    "retrieval_model.update_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159dfdd8",
   "metadata": {},
   "source": [
    "## Ranking Model (Deep Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b81bfa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(keras.Model):\n",
    "    def __init__(self, num_users, num_products, embedding_dim=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.user_embedding = layers.Embedding(num_users, embedding_dim)\n",
    "        self.product_embedding = layers.Embedding(num_products, embedding_dim)\n",
    "        self.ratings = keras.Sequential([\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_emb = self.user_embedding(inputs[:, 0])\n",
    "        product_emb = self.product_embedding(inputs[:, 1])\n",
    "        concat = keras.ops.concatenate([user_emb, product_emb], axis=1)\n",
    "        return self.ratings(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "954f77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 3.1762e-05 - root_mean_squared_error: 0.0054 - val_loss: 2.3276e-06 - val_root_mean_squared_error: 0.0015\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 3.1762e-05 - root_mean_squared_error: 0.0054 - val_loss: 2.3276e-06 - val_root_mean_squared_error: 0.0015\n",
      "Epoch 2/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 5.3604e-06 - root_mean_squared_error: 0.0023 - val_loss: 9.5828e-07 - val_root_mean_squared_error: 9.7892e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 5.3604e-06 - root_mean_squared_error: 0.0023 - val_loss: 9.5828e-07 - val_root_mean_squared_error: 9.7892e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 6.2525e-06 - root_mean_squared_error: 0.0024 - val_loss: 6.3531e-07 - val_root_mean_squared_error: 7.9706e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 6.2525e-06 - root_mean_squared_error: 0.0024 - val_loss: 6.3531e-07 - val_root_mean_squared_error: 7.9706e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 7.1290e-06 - root_mean_squared_error: 0.0025 - val_loss: 4.9331e-07 - val_root_mean_squared_error: 7.0236e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 7.1290e-06 - root_mean_squared_error: 0.0025 - val_loss: 4.9331e-07 - val_root_mean_squared_error: 7.0236e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 3.8396e-06 - root_mean_squared_error: 0.0018 - val_loss: 4.2242e-07 - val_root_mean_squared_error: 6.4994e-04\n",
      "\u001b[1m4974/4974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 3.8396e-06 - root_mean_squared_error: 0.0018 - val_loss: 4.2242e-07 - val_root_mean_squared_error: 6.4994e-04\n"
     ]
    }
   ],
   "source": [
    "ranking_model = RankingModel(num_users, num_products, embedding_dim=32)\n",
    "ranking_model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=0.05),\n",
    ")\n",
    "ranking_history = ranking_model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48164a5",
   "metadata": {},
   "source": [
    "## Beyond-Accuracy Metrics with KerasRS\n",
    "\n",
    "KerasRS provides advanced metrics such as Mean Reciprocal Rank (MRR), nDCG, and coverage/diversity. For production, consider using these for a more holistic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424a8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_rs.metrics import MeanReciprocalRank , NDCG\n",
    "\n",
    "# Example instantiation (adapt for your evaluation pipeline)\n",
    "mrr_metric = MeanReciprocalRank()\n",
    "ndcg_metric = NDCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802849",
   "metadata": {},
   "source": [
    "## References\n",
    "- [KerasRS API Documentation](https://keras.io/keras_rs/api/)\n",
    "- [KerasRS Basic Retrieval Example](https://keras.io/keras_rs/examples/basic_retrieval/)\n",
    "- [KerasRS Basic Ranking Example](https://keras.io/keras_rs/examples/basic_ranking/)\n",
    "- [KerasRS Deep Recommender Example](https://keras.io/keras_rs/examples/deep_recommender/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81c5f4",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation with KerasRS\n",
    "\n",
    "Let's evaluate our models using advanced ranking metrics provided by KerasRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e55830e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranking Model Performance:\n",
      "Mean Reciprocal Rank (MRR): 0.0000\n",
      "Mean Average Precision (MAP): 0.0000\n",
      "Discounted Cumulative Gain (DCG): 0.0001\n",
      "Normalized DCG (nDCG): 0.1811\n"
     ]
    }
   ],
   "source": [
    "from keras_rs.metrics import MeanReciprocalRank, MeanAveragePrecision, DCG, NDCG\n",
    "\n",
    "def get_ranking_eval_data(model, X, y, num_products, group_size=20):\n",
    "    # For a subset of users, get predictions for all products\n",
    "    user_indices = np.unique(X[:, 0])\n",
    "    np.random.shuffle(user_indices)\n",
    "    user_indices = user_indices[:group_size]\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for user in user_indices:\n",
    "        # All products for this user\n",
    "        user_mask = X[:, 0] == user\n",
    "        user_products = X[user_mask][:, 1]\n",
    "        # Build a full list of all products for this user\n",
    "        all_products = np.arange(num_products)\n",
    "        labels = np.zeros(num_products)\n",
    "        labels[user_products] = y[user_mask]\n",
    "        # Predict for all products\n",
    "        user_input = np.column_stack([np.repeat(user, num_products), all_products])\n",
    "        scores = model.predict(user_input, verbose=0).flatten()\n",
    "        y_true.append(labels)\n",
    "        y_pred.append(scores)\n",
    "    \n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# Evaluate Ranking Model\n",
    "y_true, y_pred = get_ranking_eval_data(ranking_model, X_test, y_test, num_products)\n",
    "\n",
    "# Initialize and compute metrics\n",
    "mrr = MeanReciprocalRank()(y_true, y_pred)\n",
    "map_score = MeanAveragePrecision()(y_true, y_pred)\n",
    "dcg = DCG()(y_true, y_pred)\n",
    "ndcg = NDCG()(y_true, y_pred)\n",
    "\n",
    "print(\"\\nRanking Model Performance:\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n",
    "print(f\"Discounted Cumulative Gain (DCG): {dcg:.4f}\")\n",
    "print(f\"Normalized DCG (nDCG): {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e59ff9",
   "metadata": {},
   "source": [
    "## Generate and Evaluate Recommendations\n",
    "\n",
    "Let's generate recommendations for sample users and evaluate their quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce2a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Recommendations for User 17850.0:\n",
      "  StockCode                         Description  UnitPrice  Predicted_Score\n",
      "0     22291      HANGING CHICK CREAM DECORATION       1.45         0.002746\n",
      "1    35610C      WHITE CHRISTMAS FLOCK DROPLET        1.25         0.002401\n",
      "2        C2                            CARRIAGE      50.00         0.002212\n",
      "3     84813       SET OF 4 DIAMOND NAPKIN RINGS      12.75         0.001945\n",
      "4     20983  12 PENCILS TALL TUBE RED RETROSPOT       0.85         0.001808\n",
      "5     23166      MEDIUM CERAMIC TOP STORAGE JAR       1.04         0.001723\n",
      "6     21503                       TOYBOX  WRAP        0.42         0.001700\n",
      "7     22367     CHILDRENS APRON SPACEBOY DESIGN       1.95         0.001650\n",
      "8     22649        STRAWBERRY FAIRY CAKE TEAPOT       4.95         0.001642\n",
      "9     22307    GOLD MUG BONE CHINA TREE OF LIFE       1.95         0.001534\n",
      "\n",
      "User's Actual Purchases:\n",
      "     StockCode                          Description  UnitPrice  Quantity\n",
      "0       85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55         6\n",
      "1        71053                  WHITE METAL LANTERN       3.39         6\n",
      "2       84406B       CREAM CUPID HEARTS COAT HANGER       2.75         8\n",
      "3       84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39         6\n",
      "4       84029E       RED WOOLLY HOTTIE WHITE HEART.       3.39         6\n",
      "5        22752         SET 7 BABUSHKA NESTING BOXES       7.65         2\n",
      "6        21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         6\n",
      "7        22633               HAND WARMER UNION JACK       1.85         6\n",
      "8        22632            HAND WARMER RED POLKA DOT       1.85         6\n",
      "52       20679                EDWARDIAN PARASOL RED       4.95         6\n",
      "53       37370           RETRO COFFEE MUGS ASSORTED       1.06         6\n",
      "54       21871                  SAVE THE PLANET MUG       1.06         6\n",
      "55       21071       VINTAGE BILLBOARD DRINK ME MUG       1.06         6\n",
      "56       21068      VINTAGE BILLBOARD LOVE/HATE MUG       1.06         6\n",
      "57       82483   WOOD 2 DRAWER CABINET WHITE FINISH       4.95         2\n",
      "58       82486    WOOD S/3 CABINET ANT WHITE FINISH       6.95         4\n",
      "59       82482    WOODEN PICTURE FRAME WHITE FINISH       2.10         6\n",
      "60      82494L          WOODEN FRAME ANTIQUE WHITE        2.55         6\n",
      "281    15056BL              EDWARDIAN PARASOL BLACK       4.95         6\n",
      "290     82494L          WOODEN FRAME ANTIQUE WHITE        2.55        12\n",
      "294      22803             IVORY EMBROIDERED QUILT       35.75         2\n",
      "416     85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55         8\n",
      "417      71053                  WHITE METAL LANTERN       3.39         8\n",
      "424      82483   WOOD 2 DRAWER CABINET WHITE FINISH       4.95         4\n",
      "3121     82486    WOOD S/3 CABINET ANT WHITE FINISH       6.95         2\n",
      "3124     22411    JUMBO SHOPPER VINTAGE RED PAISLEY       1.65         6\n",
      "3129     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         4\n",
      "3194    84406B       CREAM CUPID HEARTS COAT HANGER       2.75         6\n",
      "3804    84029E       RED WOOLLY HOTTIE WHITE HEART.       3.39         8\n",
      "3805     22752         SET 7 BABUSHKA NESTING BOXES       7.65         4\n",
      "3808    85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.55        12\n",
      "3809     71053                  WHITE METAL LANTERN       3.39        12\n",
      "3820    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39         8\n",
      "4179     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25         8\n",
      "4526    85123A   WHITE HANGING HEART T-LIGHT HOLDER       2.95        12\n",
      "4528    84406B       CREAM CUPID HEARTS COAT HANGER       2.75        12\n",
      "4531     37370           RETRO COFFEE MUGS ASSORTED       1.06        12\n",
      "4532     21071       VINTAGE BILLBOARD DRINK ME MUG       1.06        12\n",
      "4533     21068      VINTAGE BILLBOARD LOVE/HATE MUG       1.06        12\n",
      "4538    84029G  KNITTED UNION FLAG HOT WATER BOTTLE       3.39        12\n",
      "4541     22803             IVORY EMBROIDERED QUILT       35.75         3\n",
      "4542     21730    GLASS STAR FROSTED T-LIGHT HOLDER       4.25        12\n",
      "4543     22632            HAND WARMER RED POLKA DOT       1.85        12\n",
      "4544     22633               HAND WARMER UNION JACK       1.85        12\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(model, user_id, df, customer2idx, product2idx, top_n=10):\n",
    "    \"\"\"Generate top-N recommendations for a specific user.\"\"\"\n",
    "    user_idx = customer2idx[user_id]\n",
    "    all_products = np.arange(len(product2idx))\n",
    "    user_input = np.column_stack([np.repeat(user_idx, len(product2idx)), all_products])\n",
    "    scores = model.predict(user_input, verbose=0).flatten()\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "    idx2product = {v: k for k, v in product2idx.items()}\n",
    "    recommended_products = [idx2product[idx] for idx in top_indices]\n",
    "    \n",
    "    # Create recommendations dataframe\n",
    "    recommendations_data = []\n",
    "    for idx, product_id in zip(top_indices, recommended_products):\n",
    "        product_info = df[df['StockCode'] == product_id].iloc[0]\n",
    "        recommendations_data.append({\n",
    "            'StockCode': product_id,\n",
    "            'Description': product_info['Description'],\n",
    "            'UnitPrice': product_info['UnitPrice'],\n",
    "            'Predicted_Score': scores[idx]\n",
    "        })\n",
    "    \n",
    "    recommendations = pd.DataFrame(recommendations_data)\n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations for a sample user\n",
    "sample_user_id = df['CustomerID'].iloc[0]\n",
    "recommendations = get_recommendations(ranking_model, sample_user_id, df, customer2idx, product2idx)\n",
    "\n",
    "print(f\"\\nTop 10 Recommendations for User {sample_user_id}:\")\n",
    "print(recommendations)\n",
    "\n",
    "# Get user's actual purchases for comparison\n",
    "user_actual = df[df['CustomerID'] == sample_user_id][\n",
    "    ['StockCode', 'Description', 'UnitPrice', 'Quantity']\n",
    "].drop_duplicates()\n",
    "print(f\"\\nUser's Actual Purchases:\")\n",
    "print(user_actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
